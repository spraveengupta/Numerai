{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(\"/Users/PraveenGupta/Downloads/Kaggle/numerai_datasets/\")\n",
    "\n",
    "\n",
    "train=pd.read_csv(\"numerai_training_data.csv\")\n",
    "test=pd.read_csv(\"numerai_tournament_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_id</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>0.263669</td>\n",
       "      <td>0.711012</td>\n",
       "      <td>0.730641</td>\n",
       "      <td>0.259069</td>\n",
       "      <td>0.331150</td>\n",
       "      <td>0.300947</td>\n",
       "      <td>0.468118</td>\n",
       "      <td>0.426362</td>\n",
       "      <td>0.545662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869772</td>\n",
       "      <td>0.219606</td>\n",
       "      <td>0.690553</td>\n",
       "      <td>0.697929</td>\n",
       "      <td>0.332535</td>\n",
       "      <td>0.500681</td>\n",
       "      <td>0.418926</td>\n",
       "      <td>0.272475</td>\n",
       "      <td>0.822392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2</td>\n",
       "      <td>0.828056</td>\n",
       "      <td>0.433518</td>\n",
       "      <td>0.435617</td>\n",
       "      <td>0.209394</td>\n",
       "      <td>0.508133</td>\n",
       "      <td>0.296114</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.876144</td>\n",
       "      <td>0.201528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.235018</td>\n",
       "      <td>0.588986</td>\n",
       "      <td>0.767599</td>\n",
       "      <td>0.585097</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.960031</td>\n",
       "      <td>0.732236</td>\n",
       "      <td>0.543159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3</td>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.590072</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.921637</td>\n",
       "      <td>0.542368</td>\n",
       "      <td>0.729199</td>\n",
       "      <td>0.979151</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847301</td>\n",
       "      <td>0.894065</td>\n",
       "      <td>0.791371</td>\n",
       "      <td>0.721615</td>\n",
       "      <td>0.202686</td>\n",
       "      <td>0.845608</td>\n",
       "      <td>0.046535</td>\n",
       "      <td>0.200791</td>\n",
       "      <td>0.654688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>0.796596</td>\n",
       "      <td>0.276844</td>\n",
       "      <td>0.234234</td>\n",
       "      <td>0.798410</td>\n",
       "      <td>0.129723</td>\n",
       "      <td>0.794306</td>\n",
       "      <td>0.174816</td>\n",
       "      <td>0.823313</td>\n",
       "      <td>0.209920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094406</td>\n",
       "      <td>0.817543</td>\n",
       "      <td>0.342794</td>\n",
       "      <td>0.215916</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.207310</td>\n",
       "      <td>0.845106</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.016130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A5</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.036370</td>\n",
       "      <td>0.438090</td>\n",
       "      <td>0.219633</td>\n",
       "      <td>0.100569</td>\n",
       "      <td>0.097791</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.337548</td>\n",
       "      <td>0.382942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074038</td>\n",
       "      <td>0.044325</td>\n",
       "      <td>0.844283</td>\n",
       "      <td>0.792098</td>\n",
       "      <td>0.842606</td>\n",
       "      <td>0.133044</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.795792</td>\n",
       "      <td>0.128112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  t_id  feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0   A1  0.263669  0.711012  0.730641  0.259069  0.331150  0.300947  0.468118   \n",
       "1   A2  0.828056  0.433518  0.435617  0.209394  0.508133  0.296114  0.082211   \n",
       "2   A3  0.089681  0.590072  0.715500  0.921637  0.542368  0.729199  0.979151   \n",
       "3   A4  0.796596  0.276844  0.234234  0.798410  0.129723  0.794306  0.174816   \n",
       "4   A5  0.040664  0.036370  0.438090  0.219633  0.100569  0.097791  0.089305   \n",
       "\n",
       "   feature8  feature9   ...    feature13  feature14  feature15  feature16  \\\n",
       "0  0.426362  0.545662   ...     0.869772   0.219606   0.690553   0.697929   \n",
       "1  0.876144  0.201528   ...     0.570470   0.235018   0.588986   0.767599   \n",
       "2  0.009172  0.929291   ...     0.847301   0.894065   0.791371   0.721615   \n",
       "3  0.823313  0.209920   ...     0.094406   0.817543   0.342794   0.215916   \n",
       "4  0.337548  0.382942   ...     0.074038   0.044325   0.844283   0.792098   \n",
       "\n",
       "   feature17  feature18  feature19  feature20  feature21  target  \n",
       "0   0.332535   0.500681   0.418926   0.272475   0.822392       1  \n",
       "1   0.585097   0.458801   0.960031   0.732236   0.543159       0  \n",
       "2   0.202686   0.845608   0.046535   0.200791   0.654688       0  \n",
       "3   0.015114   0.207310   0.845106   0.017104   0.016130       0  \n",
       "4   0.842606   0.133044   0.002375   0.795792   0.128112       1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_id</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature12</th>\n",
       "      <th>feature13</th>\n",
       "      <th>feature14</th>\n",
       "      <th>feature15</th>\n",
       "      <th>feature16</th>\n",
       "      <th>feature17</th>\n",
       "      <th>feature18</th>\n",
       "      <th>feature19</th>\n",
       "      <th>feature20</th>\n",
       "      <th>feature21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8309</td>\n",
       "      <td>0.853061</td>\n",
       "      <td>0.991828</td>\n",
       "      <td>0.350143</td>\n",
       "      <td>0.654192</td>\n",
       "      <td>0.909093</td>\n",
       "      <td>0.862609</td>\n",
       "      <td>0.463147</td>\n",
       "      <td>0.911227</td>\n",
       "      <td>0.406167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925065</td>\n",
       "      <td>0.913353</td>\n",
       "      <td>0.653512</td>\n",
       "      <td>0.962262</td>\n",
       "      <td>0.95163</td>\n",
       "      <td>0.886714</td>\n",
       "      <td>0.352522</td>\n",
       "      <td>0.108802</td>\n",
       "      <td>0.945558</td>\n",
       "      <td>0.007984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_id  feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0  8309  0.853061  0.991828  0.350143  0.654192  0.909093  0.862609  0.463147   \n",
       "\n",
       "   feature8  feature9    ...      feature12  feature13  feature14  feature15  \\\n",
       "0  0.911227  0.406167    ...       0.925065   0.913353   0.653512   0.962262   \n",
       "\n",
       "   feature16  feature17  feature18  feature19  feature20  feature21  \n",
       "0    0.95163   0.886714   0.352522   0.108802   0.945558   0.007984  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = 'target'\n",
    "IDCol = ['t_id']\n",
    "predictors=[x for x in train.columns if x not in [target]+IDCol+[\"predictions\"]]\n",
    "\n",
    "from sklearn import cross_validation, metrics\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def modelfit(alg,dtrain,dtest,predictors,target,IDCol,filename):\n",
    "    #fit the algorithm on the data\n",
    "    print datetime.now().time()\n",
    "    alg.fit(dtrain[predictors],dtrain[target])\n",
    "    \n",
    "    #predict training data set\n",
    "    dtrain[\"predictions\"] = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #performs cross validation\n",
    "    cv_score = cross_validation.cross_val_score(alg,dtrain[predictors],dtrain[target],cv=7,scoring='log_loss')\n",
    "    \n",
    "    #Print model report\n",
    "    print \"\\nModel Report :\"\n",
    "    print \"Train Log Loss : %.4g\" % (metrics.log_loss(dtrain[target].values,dtrain[\"predictions\"].values))\n",
    "    print \"CV Score : Mean - %.4g | Std - %.4g | Min - %.4g | Max - %.4g\"%(np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score))\n",
    "    \n",
    "    #Predict on testing data\n",
    "    dtest[target]=alg.predict_proba(dtest[predictors])[:,1]\n",
    "    \n",
    "    #Export submission file\n",
    "    IDCol.append(target)\n",
    "    submission = pd.DataFrame({x : dtest[x] for x in IDCol})\n",
    "    submission = submission.rename(columns={'target': 'probability'})\n",
    "    if not os.path.exists(\"submission\"):\n",
    "        os.makedirs(\"submission\")\n",
    "    submission.to_csv(\"submission/\"+filename,index=False)\n",
    "    \n",
    "    \n",
    "    cv = pd.DataFrame(dtrain[['t_id','predictions']])\n",
    "    cv = cv.rename(columns={'predictions': \"CV_\"+filename[:-4]})\n",
    "    if not os.path.exists(\"CV\"):\n",
    "        os.makedirs(\"CV\")\n",
    "    cv.to_csv(\"CV/\"+\"CV_\"+filename,index=False)\n",
    "    \n",
    "    print datetime.now().time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:05:10.766000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.6911\n",
      "CV Score : Mean - -0.6916 | Std - 0.0004243 | Min - -0.6924 | Max - -0.6909\n",
      "12:05:15.396000\n"
     ]
    }
   ],
   "source": [
    "# LB = 0.69915; CV = -0.6915\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "alg3=LogisticRegression()\n",
    "modelfit(alg3,train,test,predictors,target,IDCol,'alg_Logistic.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:05:21.967000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.6897\n",
      "CV Score : Mean - -0.6939 | Std - 0.0006295 | Min - -0.6949 | Max - -0.6931\n",
      "12:05:23.359000\n"
     ]
    }
   ],
   "source": [
    "# LB = 18.2; CV = -17.06\n",
    "# Looking weird.. CV.. Need to analyze further\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "alg2R=DecisionTreeClassifier(max_depth=5,min_samples_split=50, min_samples_leaf=25,max_features='sqrt',random_state=111)\n",
    "modelfit(alg2R,train,test,predictors,target,IDCol,'alg_DTree.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:06:23.981000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.6912\n",
      "CV Score : Mean - -0.6925 | Std - 0.0004172 | Min - -0.6929 | Max - -0.6918\n",
      "12:06:24.844000\n"
     ]
    }
   ],
   "source": [
    "# LB = 18.3; CV = -17.07\n",
    "#####\n",
    "# (max_depth=5,min_samples_split=50, min_samples_leaf=25,max_features='sqrt')\n",
    "# LB = 0.69736; CV = -0.6924\n",
    "#####\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "algET=ExtraTreeClassifier(max_depth=5,min_samples_split=50, min_samples_leaf=25,max_features='sqrt',random_state=111)\n",
    "modelfit(algET,train,test,predictors,target,IDCol,'alg_ET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:07:36.762000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.688\n",
      "CV Score : Mean - -0.6914 | Std - 0.0004759 | Min - -0.6924 | Max - -0.6907\n",
      "12:07:44.333000\n"
     ]
    }
   ],
   "source": [
    "# CV = -0.8054, LB=0.79851\n",
    "#####\n",
    "# (n_estimators=20,max_depth=5,min_samples_split=50, min_samples_leaf=25,max_features='sqrt',n_jobs=4)\n",
    "# CV = -0.6914, LB=0.69810\n",
    "#####\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "alg1=RandomForestClassifier(n_estimators=20,max_depth=5,min_samples_split=50, min_samples_leaf=25,max_features='sqrt',n_jobs=4,random_state=111)\n",
    "modelfit(alg1,train,test,predictors,target,IDCol,'alg_RandomForest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:09:53.100000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.6619\n",
      "CV Score : Mean - -0.716 | Std - 0.002644 | Min - -0.7201 | Max - -0.7129\n",
      "12:13:32.782000\n"
     ]
    }
   ],
   "source": [
    "# CV = -1.792, LB = 1.68391\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "algKNN=KNeighborsClassifier(leaf_size=100,n_jobs=4,n_neighbors=20)\n",
    "modelfit(algKNN,train,test,predictors,target,IDCol,'alg_KNN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:15:04.479000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.701\n",
      "CV Score : Mean - -0.7017 | Std - 0.002806 | Min - -0.7077 | Max - -0.6987\n",
      "12:15:05.514000\n"
     ]
    }
   ],
   "source": [
    "# CV = -0.7017, LB = 0.72670\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "algGNB=GaussianNB()\n",
    "modelfit(algGNB,train,test,predictors,target,IDCol,'alg_GNB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:15:07.900000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.6931\n",
      "CV Score : Mean - -0.6931 | Std - 6.467e-06 | Min - -0.6931 | Max - -0.6931\n",
      "12:31:20.749000\n",
      "12:31:20.750000\n"
     ]
    }
   ],
   "source": [
    "# CV = 0.6931, LB = 0.69323\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "alg3=LogisticRegression(solver='sag')#n_estimators=100,max_depth=3,min_samples_leaf=100,n_jobs=4)\n",
    "ada1=AdaBoostClassifier(base_estimator=alg3)\n",
    "modelfit(ada1,train,test,predictors,target,IDCol,'alg_Logistic_AdaB.csv')\n",
    "print datetime.now().time()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# combine DTree + Logistic\n",
    "# Change modelfit code in such a way that it provides cv files as well\n",
    "# apply minmax transformation etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:32:37.205000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.688\n",
      "CV Score : Mean - -0.6914 | Std - 0.0004759 | Min - -0.6924 | Max - -0.6907\n",
      "12:32:44.573000\n"
     ]
    }
   ],
   "source": [
    "# CV = -0.6921,  LB = 0.69875\n",
    "from sklearn.svm import SVC\n",
    "alg8=SVC(random_state=111)\n",
    "modelfit(alg1,train,test,predictors,target,IDCol,'alg_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:33:11.432000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.688\n",
      "CV Score : Mean - -0.6914 | Std - 0.0004759 | Min - -0.6924 | Max - -0.6907\n",
      "12:33:18.945000\n"
     ]
    }
   ],
   "source": [
    "# CV = -0.6921 LB = 0.69875\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "alg8=SGDClassifier(loss='log')\n",
    "modelfit(alg1,train,test,predictors,target,IDCol,'alg_SGD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:33:26.400000\n",
      "12:33:26.400000\n",
      "\n",
      "Model Report :\n",
      "Train Log Loss : 0.6828\n",
      "CV Score : Mean - -0.6921 | Std - 0.0006316 | Min - -0.6934 | Max - -0.6913\n",
      "12:35:56.780000\n",
      "12:35:56.781000\n"
     ]
    }
   ],
   "source": [
    "# CV = -0.6921 LB = 0.69875\n",
    "print datetime.now().time()\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "alg1=GradientBoostingClassifier(random_state=111)\n",
    "modelfit(alg1,train,test,predictors,target,IDCol,'alg_GBM.csv')\n",
    "print datetime.now().time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for xgboost\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "predictors=[x for x in train.columns if x not in [target]+IDCol+[\"predictions\"]]\n",
    "def xGBmodelfit(alg,dtrain,dtest,predictors,filename,useTrainCV=True, cv_folds=5,early_stopping_rounds=200):\n",
    "    print datetime.now().time()\n",
    "    if useTrainCV:\n",
    "        xgb_param=alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values,label = dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param,xgtrain,num_boost_round=alg.get_params()['n_estimators'],\n",
    "            nfold=cv_folds,metrics='logloss',early_stopping_rounds=early_stopping_rounds)#,show_progress=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])#,booster='gbtree')\n",
    "    \n",
    "    bestNoOfRounds = cvresult['test-logloss-mean'].argmax()\n",
    "    bestAnsForThisSetting =  cvresult.ix[bestNoOfRounds]\n",
    "    bestModelEval = bestAnsForThisSetting[0]\n",
    "    print \"Best Num of Rounds %.7g\" %bestNoOfRounds\n",
    "#     print \"Best Ans %.7g\" %bestAnsForThisSetting\n",
    "    print \"Best Model Eval (Test-LogLoss) %.7g\" %bestModelEval\n",
    "    \n",
    "    alg.fit(dtrain[predictors],dtrain[target],eval_metric='logloss')#,eta=0.0001)\n",
    "    \n",
    "#   Predicting training data\n",
    "    dtrain[\"predictions\"] = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob=alg.predict_proba(dtrain[predictors])[:,1]       \n",
    "    \n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" %metrics.accuracy_score(dtrain[target],dtrain[\"predictions\"].values)\n",
    "    print \"LogLoss Score (train) : %f\" %metrics.log_loss(dtrain[target],dtrain_predprob)\n",
    "    \n",
    "#   Feature important plot\n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar',title = 'Feature Importance')\n",
    "    plt.ylabel('Feature Importance score')\n",
    "    \n",
    "    #Predict on testing data\n",
    "    dtest[target]=alg.predict_proba(dtest[predictors])[:,1]\n",
    "    \n",
    "    #Export submission file\n",
    "    IDCol.append(target)\n",
    "    submission = pd.DataFrame({x : dtest[x] for x in IDCol})\n",
    "    submission = submission.rename(columns={'target': 'probability'})\n",
    "    \n",
    "    if not os.path.exists(\"submission\"):\n",
    "        os.makedirs(\"submission\")\n",
    "    submission.to_csv(\"submission/\"+filename,index=False)\n",
    "    \n",
    "    cv = pd.DataFrame(dtrain[['t_id','predictions']])\n",
    "    cv = cv.rename(columns={'predictions': \"CV_\"+filename[:-4]})\n",
    "    if not os.path.exists(\"CV\"):\n",
    "        os.makedirs(\"CV\")\n",
    "    cv.to_csv(\"CV/\"+\"CV_\"+filename,index=False)\n",
    "    \n",
    "    print datetime.now().time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t_id',\n",
       " 'feature1',\n",
       " 'feature2',\n",
       " 'feature3',\n",
       " 'feature4',\n",
       " 'feature5',\n",
       " 'feature6',\n",
       " 'feature7',\n",
       " 'feature8',\n",
       " 'feature9',\n",
       " 'feature10',\n",
       " 'feature11',\n",
       " 'feature12',\n",
       " 'feature13',\n",
       " 'feature14',\n",
       " 'feature15',\n",
       " 'feature16',\n",
       " 'feature17',\n",
       " 'feature18',\n",
       " 'feature19',\n",
       " 'feature20',\n",
       " 'feature21',\n",
       " 'predictions']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:42:00.545000\n",
      "Best Num of Rounds 0\n",
      "Best Model Eval (Test-LogLoss) 0.6929616\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.6274\n",
      "LogLoss Score (train) : 0.666240\n",
      "12:42:37.086000\n"
     ]
    }
   ],
   "source": [
    "# CV = 0.6929616, LB = 0.69468\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    "objective = 'binary:logistic',\n",
    "learning_rate=0.05,\n",
    "n_estimators = 200,\n",
    "max_depth=5,\n",
    "min_child_weight=5,\n",
    "subsample=0.8,\n",
    "colsample_bytree=0.5,\n",
    "nthread=4,\n",
    "seed=27)\n",
    "\n",
    "xGBmodelfit(xgb1,train,test,predictors,'xgBoost.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
